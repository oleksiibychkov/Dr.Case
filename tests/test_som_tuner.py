"""
–¢–µ—Å—Ç–∏ –¥–ª—è –º–æ–¥—É–ª—è optimization/som_tuner

–ó–∞–ø—É—Å–∫: pytest tests/test_som_tuner.py -v
–ê–±–æ –¥–µ–º–æ: python tests/test_som_tuner.py
"""

from pathlib import Path
import tempfile

# –®–ª—è—Ö –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
DATA_PATH = Path(__file__).parent.parent / "data" / "unified_disease_symptom_data_full.json"


def test_tuner_creation():
    """–¢–µ—Å—Ç —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è SOMTuner"""
    from dr_case.optimization import SOMTuner
    
    if not DATA_PATH.exists():
        print(f"‚ö† Skipping: {DATA_PATH} not found")
        return None
    
    tuner = SOMTuner(
        database_path=str(DATA_PATH),
        target_recall=0.99,
        max_candidates_ratio=0.15
    )
    
    assert tuner.n_diseases == 842
    assert tuner.n_symptoms == 461
    
    print(f"‚úì SOMTuner created: {tuner}")
    print(f"  Train size: {len(tuner.train_indices)}")
    print(f"  Validation size: {len(tuner.val_indices)}")
    
    return tuner


def test_quick_optimization():
    """–¢–µ—Å—Ç —à–≤–∏–¥–∫–æ—ó –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó (–º–∞–ª–æ trials)"""
    from dr_case.optimization import SOMTuner
    
    if not DATA_PATH.exists():
        print(f"‚ö† Skipping: {DATA_PATH} not found")
        return None
    
    tuner = SOMTuner(
        database_path=str(DATA_PATH),
        target_recall=0.95,  # –ù–∏–∂—á–∏–π –ø–æ—Ä—ñ–≥ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ç–µ—Å—Ç—É
        max_candidates_ratio=0.20
    )
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –∑ –º—ñ–Ω—ñ–º—É–º–æ–º trials
    print("\n--- Running quick optimization (5 trials) ---")
    result = tuner.quick_tune(n_trials=5)
    
    assert result.best_value > 0
    assert "recall" in result.best_metrics
    assert result.n_trials == 5
    
    print(f"\n‚úì Quick optimization complete")
    print(f"  Best score: {result.best_value:.4f}")
    print(f"  Best recall: {result.best_metrics['recall']:.2%}")
    print(f"  Best candidates: {result.best_metrics['avg_candidates']:.1f}")
    print(f"  Best grid: {result.best_params['grid_size']}x{result.best_params['grid_size']}")
    
    return result


def test_get_best_model():
    """–¢–µ—Å—Ç –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–∞–π–∫—Ä–∞—â–æ—ó –º–æ–¥–µ–ª—ñ"""
    from dr_case.optimization import SOMTuner
    
    if not DATA_PATH.exists():
        print(f"‚ö† Skipping: {DATA_PATH} not found")
        return None
    
    tuner = SOMTuner(database_path=str(DATA_PATH))
    
    # –®–≤–∏–¥–∫–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
    tuner.quick_tune(n_trials=3)
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –º–æ–¥–µ–ª—å
    som, projector = tuner.get_best_model()
    
    assert som.is_trained
    assert projector is not None
    
    print(f"‚úì Got best model: {som}")
    
    return som, projector


def test_train_with_best_params():
    """–¢–µ—Å—Ç –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    from dr_case.optimization import SOMTuner
    
    if not DATA_PATH.exists():
        print(f"‚ö† Skipping: {DATA_PATH} not found")
        return None
    
    tuner = SOMTuner(database_path=str(DATA_PATH))
    
    # –®–≤–∏–¥–∫–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
    result = tuner.quick_tune(n_trials=3)
    
    # –ù–∞–≤—á–∞—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å
    print("\n--- Training final model ---")
    som, projector, metrics = tuner.train_with_best_params()
    
    assert som.is_trained
    assert metrics["recall"] > 0
    
    print(f"‚úì Final model trained")
    print(f"  Recall: {metrics['recall']:.2%}")
    print(f"  Avg candidates: {metrics['avg_candidates']:.1f}")
    
    return som, projector, metrics


def test_save_load_result():
    """–¢–µ—Å—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
    from dr_case.optimization import SOMTuner, TuningResult
    
    if not DATA_PATH.exists():
        print(f"‚ö† Skipping: {DATA_PATH} not found")
        return None
    
    tuner = SOMTuner(database_path=str(DATA_PATH))
    result = tuner.quick_tune(n_trials=3)
    
    with tempfile.TemporaryDirectory() as tmpdir:
        path = Path(tmpdir) / "tuning_result.json"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ
        result.save(str(path))
        assert path.exists()
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ
        loaded = TuningResult.load(str(path))
        
        assert loaded.best_value == result.best_value
        assert loaded.best_params == result.best_params
        
        print(f"‚úì Save/Load test passed")
    
    return True


def demo():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –º–æ–¥—É–ª—è som_tuner"""
    print("=" * 60)
    print("Dr.Case ‚Äî –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è SOM Tuner")
    print("=" * 60)
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
    if not DATA_PATH.exists():
        print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!")
        print(f"   –û—á—ñ–∫—É–≤–∞–Ω–∏–π —à–ª—è—Ö: {DATA_PATH}")
        return False
    
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Optuna
        try:
            import optuna
            print(f"\n‚úì Optuna version: {optuna.__version__}")
        except ImportError:
            print("\n‚ùå Optuna –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í–∏–∫–æ–Ω–∞–π—Ç–µ: pip install optuna")
            return False
        
        print("\n--- 1. Creating SOMTuner ---")
        tuner = test_tuner_creation()
        
        if tuner is None:
            return False
        
        print("\n--- 2. Quick Optimization ---")
        result = test_quick_optimization()
        
        print("\n--- 3. Train Final Model ---")
        test_train_with_best_params()
        
        print("\n--- 4. Save/Load Result ---")
        test_save_load_result()
        
        print("\n" + "=" * 60)
        print("‚úÖ –í—Å—ñ —Ç–µ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        print("=" * 60)
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        if result:
            print("\nüìã –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:")
            print(f"   Grid size: {result.best_params['grid_size']}x{result.best_params['grid_size']}")
            print(f"   Epochs: {result.best_params['epochs']}")
            print(f"   Alpha: {result.best_params['alpha']:.3f}")
            print(f"   K: {result.best_params['k']}")
            print(f"   Tau: {result.best_params['tau']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False


def full_optimization(n_trials: int = 30):
    """
    –ü–æ–≤–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (–∑–∞–ø—É—Å–∫–∞—Ç–∏ –æ–∫—Ä–µ–º–æ, –∑–∞–π–º–∞—î ~10-30 —Ö–≤–∏–ª–∏–Ω)
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
        python -c "from tests.test_som_tuner import full_optimization; full_optimization(50)"
    """
    from dr_case.optimization import SOMTuner
    
    print("=" * 60)
    print("Dr.Case ‚Äî –ü–æ–≤–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è SOM")
    print("=" * 60)
    
    tuner = SOMTuner(
        database_path=str(DATA_PATH),
        target_recall=0.995,
        max_candidates_ratio=0.12
    )
    
    # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
    result = tuner.optimize(n_trials=n_trials)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result.save("models/som_tuning_result.json")
    print(f"\n‚úì Result saved to models/som_tuning_result.json")
    
    # –ù–∞–≤—á–∞—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å
    som, projector, metrics = tuner.train_with_best_params()
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
    som.save("models/som_optimized.pkl")
    print(f"‚úì Model saved to models/som_optimized.pkl")
    
    return result


if __name__ == "__main__":
    demo()
