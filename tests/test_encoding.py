"""
–¢–µ—Å—Ç–∏ –¥–ª—è –º–æ–¥—É–ª—è encoding

–ó–∞–ø—É—Å–∫: pytest tests/test_encoding.py -v
–ê–±–æ –¥–µ–º–æ: python tests/test_encoding.py
"""

import numpy as np
from pathlib import Path

# –®–ª—è—Ö –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
DATA_PATH = Path(__file__).parent.parent / "data" / "unified_disease_symptom_data_full.json"


def test_data_loader():
    """–¢–µ—Å—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö"""
    from dr_case.encoding import DiseaseDatabaseLoader
    
    loader = DiseaseDatabaseLoader(str(DATA_PATH))
    
    print(f"‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤: {loader.disease_count}")
    print(f"‚úì –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å–∏–º–ø—Ç–æ–º—ñ–≤: {loader.symptom_count}")
    
    assert loader.disease_count > 0, "–ë–∞–∑–∞ –ø–æ—Ä–æ–∂–Ω—è!"
    assert loader.symptom_count > 0, "–ù–µ–º–∞—î —Å–∏–º–ø—Ç–æ–º—ñ–≤!"
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = loader.get_statistics()
    print(f"‚úì –°–µ—Ä–µ–¥–Ω—è –∫-—Ç—å —Å–∏–º–ø—Ç–æ–º—ñ–≤ –Ω–∞ –¥—ñ–∞–≥–Ω–æ–∑: {stats['avg_symptoms_per_disease']:.1f}")
    print(f"‚úì –ú—ñ–Ω —Å–∏–º–ø—Ç–æ–º—ñ–≤: {stats['min_symptoms']}, –ú–∞–∫—Å: {stats['max_symptoms']}")
    
    return loader


def test_symptom_vocabulary(loader):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–Ω–∏–∫–∞ —Å–∏–º–ø—Ç–æ–º—ñ–≤"""
    from dr_case.encoding import SymptomVocabulary
    
    vocab = SymptomVocabulary.from_database(str(DATA_PATH))
    
    print(f"‚úì –†–æ–∑–º—ñ—Ä —Å–ª–æ–≤–Ω–∏–∫–∞: {vocab.size}")
    
    assert vocab.size == loader.symptom_count
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó
    first_symptom = vocab.index_to_symptom(0)
    print(f"‚úì –ü–µ—Ä—à–∏–π —Å–∏–º–ø—Ç–æ–º (idx=0): {first_symptom}")
    
    idx = vocab.symptom_to_index(first_symptom)
    assert idx == 0, "–Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –ø–æ—Ä—É—à–µ–Ω–∞!"
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ—à—É–∫—É
    symptoms = vocab.symptoms[:5]
    print(f"‚úì –ü–µ—Ä—à—ñ 5 —Å–∏–º–ø—Ç–æ–º—ñ–≤: {symptoms}")
    
    return vocab


def test_disease_encoder(loader, vocab):
    """–¢–µ—Å—Ç –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤"""
    from dr_case.encoding import DiseaseEncoder
    
    encoder = DiseaseEncoder(vocab, loader)
    
    print(f"‚úì DiseaseEncoder: {encoder}")
    
    # –í—ñ–∑—å–º–µ–º–æ –ø–µ—Ä—à–∏–π –¥—ñ–∞–≥–Ω–æ–∑
    disease_name = loader.disease_names[0]
    print(f"‚úì –¢–µ—Å—Ç–æ–≤–∏–π –¥—ñ–∞–≥–Ω–æ–∑: {disease_name}")
    
    # –ö–æ–¥—É—î–º–æ
    vector = encoder.encode(disease_name)
    assert vector is not None, "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–∫–æ–¥—É–≤–∞—Ç–∏ –¥—ñ–∞–≥–Ω–æ–∑"
    assert vector.shape == (vocab.size,), f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞ —Ñ–æ—Ä–º–∞: {vector.shape}"
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ –≤–µ–∫—Ç–æ—Ä –Ω–µ –Ω—É–ª—å–æ–≤–∏–π
    nonzero = np.sum(vector > 0)
    print(f"‚úì –í–µ–∫—Ç–æ—Ä –º–∞—î {nonzero} –Ω–µ–Ω—É–ª—å–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ (—Å–∏–º–ø—Ç–æ–º—ñ–≤)")
    
    # –î–µ–∫–æ–¥—É—î–º–æ –Ω–∞–∑–∞–¥
    decoded = encoder.decode(vector)
    original = loader.get_symptoms(disease_name)
    print(f"‚úì –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö —Å–∏–º–ø—Ç–æ–º—ñ–≤: {len(original)}, –¥–µ–∫–æ–¥–æ–≤–∞–Ω–æ: {len(decoded)}")
    
    # –ú–∞—Ç—Ä–∏—Ü—è –≤—Å—ñ—Ö –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤
    matrix = encoder.encode_all()
    print(f"‚úì –ú–∞—Ç—Ä–∏—Ü—è –≤—Å—ñ—Ö –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤: shape {matrix.shape}")
    assert matrix.shape == (loader.disease_count, vocab.size)
    
    return encoder


def test_patient_encoder(vocab):
    """–¢–µ—Å—Ç –∫–æ–¥—É–≤–∞–Ω–Ω—è –ø–∞—Ü—ñ—î–Ω—Ç–∞"""
    from dr_case.encoding import PatientEncoder
    
    encoder = PatientEncoder(vocab)
    print(f"‚úì PatientEncoder: {encoder}")
    
    # –í—ñ–∑—å–º–µ–º–æ –¥–µ–∫—ñ–ª—å–∫–∞ —Å–∏–º–ø—Ç–æ–º—ñ–≤ –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞
    test_symptoms = vocab.symptoms[:3]
    print(f"‚úì –¢–µ—Å—Ç–æ–≤—ñ —Å–∏–º–ø—Ç–æ–º–∏: {test_symptoms}")
    
    # –ë—ñ–Ω–∞—Ä–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è
    vector = encoder.encode(test_symptoms)
    assert vector.shape == (vocab.size,)
    assert np.sum(vector > 0) == len(test_symptoms)
    print(f"‚úì –ë—ñ–Ω–∞—Ä–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è: {np.sum(vector > 0)} –∞–∫—Ç–∏–≤–Ω–∏—Ö")
    
    # –í–∞–≥–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è
    weighted = {s: 0.5 + 0.1*i for i, s in enumerate(test_symptoms)}
    vector_weighted = encoder.encode_weighted(weighted)
    print(f"‚úì –í–∞–≥–æ–≤–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è: {np.sum(vector_weighted > 0)} –∞–∫—Ç–∏–≤–Ω–∏—Ö")
    
    # –ó –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–º–∏ —Å–∏–º–ø—Ç–æ–º–∞–º–∏
    present = test_symptoms[:2]
    absent = test_symptoms[2:3]
    vector_neg = encoder.encode_with_negatives(present, absent)
    print(f"‚úì –ó –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–º–∏: –ø—Ä–∏—Å—É—Ç–Ω—ñ—Ö={np.sum(vector_neg > 0)}, –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö={np.sum(vector_neg < 0)}")
    
    return encoder


def demo():
    """–ü–æ–≤–Ω–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –º–æ–¥—É–ª—è encoding"""
    print("=" * 60)
    print("Dr.Case ‚Äî –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –º–æ–¥—É–ª—è encoding")
    print("=" * 60)
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
    if not DATA_PATH.exists():
        print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!")
        print(f"   –û—á—ñ–∫—É–≤–∞–Ω–∏–π —à–ª—è—Ö: {DATA_PATH}")
        print(f"   –ü–æ–∫–ª–∞–¥—ñ—Ç—å —Ñ–∞–π–ª unified_disease_symptom_data_full.json –≤ –ø–∞–ø–∫—É data/")
        return False
    
    print(f"\nüìÇ –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö: {DATA_PATH}")
    
    try:
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        print("\n--- 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö ---")
        loader = test_data_loader()
        
        # 2. –°–ª–æ–≤–Ω–∏–∫
        print("\n--- 2. –°–ª–æ–≤–Ω–∏–∫ —Å–∏–º–ø—Ç–æ–º—ñ–≤ ---")
        vocab = test_symptom_vocabulary(loader)
        
        # 3. Disease Encoder
        print("\n--- 3. –ö–æ–¥—É–≤–∞–Ω–Ω—è –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤ ---")
        disease_encoder = test_disease_encoder(loader, vocab)
        
        # 4. Patient Encoder
        print("\n--- 4. –ö–æ–¥—É–≤–∞–Ω–Ω—è –ø–∞—Ü—ñ—î–Ω—Ç–∞ ---")
        patient_encoder = test_patient_encoder(vocab)
        
        # 5. –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
        print("\n--- 5. –ü—Ä–∏–∫–ª–∞–¥: –ø–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤ ---")
        
        # –ë–µ—Ä–µ–º–æ —Å–∏–º–ø—Ç–æ–º–∏ –ø–∞—Ü—ñ—î–Ω—Ç–∞
        patient_symptoms = vocab.symptoms[:5]  # –ü–µ—Ä—à—ñ 5 —Å–∏–º–ø—Ç–æ–º—ñ–≤
        patient_vector = patient_encoder.encode(patient_symptoms)
        
        # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –∑ —É—Å—ñ–º–∞ –¥—ñ–∞–≥–Ω–æ–∑–∞–º–∏
        disease_matrix = disease_encoder.encode_all()
        
        # Cosine similarity
        patient_norm = patient_vector / (np.linalg.norm(patient_vector) + 1e-8)
        disease_norms = disease_matrix / (np.linalg.norm(disease_matrix, axis=1, keepdims=True) + 1e-8)
        similarities = disease_norms @ patient_norm
        
        # –¢–æ–ø-5 –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤
        top_indices = np.argsort(similarities)[::-1][:5]
        print(f"–°–∏–º–ø—Ç–æ–º–∏ –ø–∞—Ü—ñ—î–Ω—Ç–∞: {patient_symptoms}")
        print("–¢–æ–ø-5 –Ω–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂–∏—Ö –¥—ñ–∞–≥–Ω–æ–∑—ñ–≤:")
        for i, idx in enumerate(top_indices):
            disease_name = disease_encoder.index_to_disease(idx)
            print(f"  {i+1}. {disease_name}: {similarities[idx]:.3f}")
        
        print("\n" + "=" * 60)
        print("‚úÖ –í—Å—ñ —Ç–µ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    demo()
