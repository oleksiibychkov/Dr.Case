#!/usr/bin/env python3
"""
Dr.Case ‚Äî –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê PIPELINE
==============================

–ö—Ä–æ–∫ –∑–∞ –∫—Ä–æ–∫–æ–º –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–∂–µ–Ω –∫–æ–º–ø–æ–Ω–µ–Ω—Ç:
1. –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö —Å–∏–º–ø—Ç–æ–º—ñ–≤
2. SOM unit_to_diseases
3. Candidate selection
4. NN predictions

–ó–∞–ø—É—Å–∫:
    python scripts/diagnose_pipeline.py
"""

import sys
from pathlib import Path
import json
import pickle
import numpy as np

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def print_header(text: str):
    print("\n" + "=" * 70)
    print(f"üîç {text}")
    print("=" * 70)


def diagnose_database():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö"""
    print_header("–ö–†–û–ö 1: –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö")
    
    db_path = project_root / "data" / "unified_disease_symptom_merged.json"
    
    if not db_path.exists():
        print(f"   ‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {db_path}")
        return None
    
    with open(db_path, 'r', encoding='utf-8') as f:
        database = json.load(f)
    
    print(f"   ‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(database)} —Ö–≤–æ—Ä–æ–±")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–º–ø—Ç–æ–º—ñ–≤
    all_symptoms = set()
    symptoms_per_disease = []
    
    for disease, data in database.items():
        symptoms = data.get('symptoms', [])
        all_symptoms.update(symptoms)
        symptoms_per_disease.append(len(symptoms))
    
    print(f"   üìä –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å–∏–º–ø—Ç–æ–º—ñ–≤: {len(all_symptoms)}")
    print(f"   üìä –°–∏–º–ø—Ç–æ–º—ñ–≤ –Ω–∞ —Ö–≤–æ—Ä–æ–±—É: min={min(symptoms_per_disease)}, max={max(symptoms_per_disease)}, avg={np.mean(symptoms_per_disease):.1f}")
    
    # –ü—Ä–∏–∫–ª–∞–¥ —Ö–≤–æ—Ä–æ–±–∏
    example = list(database.keys())[0]
    print(f"\n   üìã –ü—Ä–∏–∫–ª–∞–¥: {example}")
    print(f"      –°–∏–º–ø—Ç–æ–º–∏: {database[example].get('symptoms', [])[:5]}...")
    
    return database


def diagnose_som():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ SOM"""
    print_header("–ö–†–û–ö 2: SOM Model")
    
    som_path = project_root / "models" / "som_merged.pkl"
    
    if not som_path.exists():
        print(f"   ‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {som_path}")
        return None
    
    with open(som_path, 'rb') as f:
        som_data = pickle.load(f)
    
    print(f"   ‚úÖ –ö–ª—é—á—ñ checkpoint: {list(som_data.keys())}")
    
    # unit_to_diseases
    unit_to_diseases = som_data.get('unit_to_diseases', {})
    print(f"   üìä unit_to_diseases: {len(unit_to_diseases)} —é–Ω—ñ—Ç—ñ–≤")
    
    if unit_to_diseases:
        # –°–∫—ñ–ª—å–∫–∏ —Ö–≤–æ—Ä–æ–± –≤ —é–Ω—ñ—Ç–∞—Ö
        diseases_counts = [len(d) for d in unit_to_diseases.values()]
        total_diseases = sum(diseases_counts)
        print(f"   üìä –í—Å—å–æ–≥–æ —Ö–≤–æ—Ä–æ–± —É —é–Ω—ñ—Ç–∞—Ö: {total_diseases}")
        print(f"   üìä –•–≤–æ—Ä–æ–± –Ω–∞ —é–Ω—ñ—Ç: min={min(diseases_counts)}, max={max(diseases_counts)}, avg={np.mean(diseases_counts):.1f}")
        
        # –ü—Ä–∏–∫–ª–∞–¥ —é–Ω—ñ—Ç–∞
        example_unit = list(unit_to_diseases.keys())[0]
        example_diseases = unit_to_diseases[example_unit]
        print(f"\n   üìã –ü—Ä–∏–∫–ª–∞–¥ —é–Ω—ñ—Ç {example_unit}: {example_diseases[:3]}...")
    
    # disease_names
    disease_names = som_data.get('disease_names', [])
    print(f"\n   üìä disease_names: {len(disease_names)} —Ö–≤–æ—Ä–æ–±")
    if disease_names:
        print(f"      –ü–µ—Ä—à—ñ 5: {disease_names[:5]}")
    
    # SOM object
    som = som_data.get('som')
    if som is not None:
        print(f"\n   üìä SOM grid: {som._weights.shape}")
    
    return som_data


def diagnose_nn():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ NN"""
    print_header("–ö–†–û–ö 3: Neural Network")
    
    nn_path = project_root / "models" / "nn_two_branch.pt"
    
    if not nn_path.exists():
        print(f"   ‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {nn_path}")
        return None
    
    import torch
    checkpoint = torch.load(nn_path, map_location='cpu', weights_only=False)
    
    print(f"   ‚úÖ –ö–ª—é—á—ñ checkpoint: {list(checkpoint.keys())}")
    
    model_config = checkpoint.get('model_config', {})
    print(f"\n   üìä model_config:")
    for k, v in model_config.items():
        print(f"      {k}: {v}")
    
    disease_names = checkpoint.get('disease_names', [])
    symptom_names = checkpoint.get('symptom_names', [])
    
    print(f"\n   üìä disease_names: {len(disease_names)}")
    print(f"   üìä symptom_names: {len(symptom_names)}")
    
    if disease_names:
        print(f"      –ü–µ—Ä—à—ñ 5 diseases: {disease_names[:5]}")
    if symptom_names:
        print(f"      –ü–µ—Ä—à—ñ 5 symptoms: {symptom_names[:5]}")
    
    return checkpoint


def diagnose_candidate_selection(database, som_data):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ candidate selection"""
    print_header("–ö–†–û–ö 4: Candidate Selection (—Ä—É—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)")
    
    if not database or not som_data:
        print("   ‚ùå –ü–æ—Ç—Ä—ñ–±–Ω—ñ database —Ç–∞ som_data")
        return
    
    from dr_case.encoding import SymptomVocabulary
    
    # –°–ª–æ–≤–Ω–∏–∫ —Å–∏–º–ø—Ç–æ–º—ñ–≤
    db_path = project_root / "data" / "unified_disease_symptom_merged.json"
    vocab = SymptomVocabulary.from_database(str(db_path))
    print(f"   üìä Vocabulary: {vocab.size} —Å–∏–º–ø—Ç–æ–º—ñ–≤")
    
    # –ë–µ—Ä–µ–º–æ —Ç–µ—Å—Ç–æ–≤—É —Ö–≤–æ—Ä–æ–±—É
    test_disease = list(database.keys())[0]
    test_symptoms = database[test_disease].get('symptoms', [])[:5]
    
    print(f"\n   üß™ –¢–µ—Å—Ç: {test_disease}")
    print(f"      –°–∏–º–ø—Ç–æ–º–∏: {test_symptoms}")
    
    # –ö–æ–¥—É—î–º–æ —Å–∏–º–ø—Ç–æ–º–∏
    symptom_vector = np.zeros(vocab.size)
    found_symptoms = []
    missing_symptoms = []
    
    for symptom in test_symptoms:
        if vocab.has_symptom(symptom):
            idx = vocab.symptom_to_index(symptom)
            symptom_vector[idx] = 1.0
            found_symptoms.append(symptom)
        else:
            missing_symptoms.append(symptom)
    
    print(f"\n   üìä –ó–Ω–∞–π–¥–µ–Ω–æ —É —Å–ª–æ–≤–Ω–∏–∫—É: {len(found_symptoms)}/{len(test_symptoms)}")
    if missing_symptoms:
        print(f"   ‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {missing_symptoms}")
    
    # –ü—Ä–æ—î–∫—Ü—ñ—è –Ω–∞ SOM
    som = som_data.get('som')
    if som is None:
        print("   ‚ùå SOM object –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        return
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    norm = np.linalg.norm(symptom_vector)
    if norm > 0:
        symptom_vector_norm = symptom_vector / norm
    else:
        symptom_vector_norm = symptom_vector
    
    # BMU
    bmu = som.winner(symptom_vector_norm)
    print(f"\n   üìä BMU (Best Matching Unit): {bmu}")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ —ñ–Ω–¥–µ–∫—Å
    grid_h, grid_w = som._weights.shape[:2]
    bmu_idx = bmu[0] * grid_w + bmu[1]
    print(f"   üìä BMU index: {bmu_idx}")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ unit_to_diseases
    unit_to_diseases = som_data.get('unit_to_diseases', {})
    
    # –ö–ª—é—á—ñ –º–æ–∂—É—Ç—å –±—É—Ç–∏ —Ä—ñ–∑–Ω–∏–º–∏
    if bmu_idx in unit_to_diseases:
        candidates = unit_to_diseases[bmu_idx]
    elif str(bmu_idx) in unit_to_diseases:
        candidates = unit_to_diseases[str(bmu_idx)]
    elif bmu in unit_to_diseases:
        candidates = unit_to_diseases[bmu]
    elif str(bmu) in unit_to_diseases:
        candidates = unit_to_diseases[str(bmu)]
    else:
        candidates = []
        print(f"\n   ‚ö†Ô∏è –Æ–Ω—ñ—Ç {bmu_idx} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ unit_to_diseases!")
        print(f"      –¢–∏–ø–∏ –∫–ª—é—á—ñ–≤: {type(list(unit_to_diseases.keys())[0]) if unit_to_diseases else 'empty'}")
        print(f"      –ü—Ä–∏–∫–ª–∞–¥ –∫–ª—é—á–∞: {list(unit_to_diseases.keys())[:3]}")
    
    print(f"\n   üìä –ö–∞–Ω–¥–∏–¥–∞—Ç–∏ –∑ —é–Ω—ñ—Ç–∞ {bmu_idx}: {len(candidates)}")
    if candidates:
        print(f"      –ü–µ—Ä—à—ñ 5: {candidates[:5]}")
        
        # –ß–∏ —î —Ü—ñ–ª—å–æ–≤–∞ —Ö–≤–æ—Ä–æ–±–∞ —Å–µ—Ä–µ–¥ –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤?
        if test_disease in candidates:
            print(f"\n   ‚úÖ {test_disease} –ó–ù–ê–ô–î–ï–ù–û —Å–µ—Ä–µ–¥ –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤!")
        else:
            print(f"\n   ‚ùå {test_disease} –ù–ï –∑–Ω–∞–π–¥–µ–Ω–æ —Å–µ—Ä–µ–¥ –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤!")
            
            # –î–µ –º–∞—î –±—É—Ç–∏ —Ü—è —Ö–≤–æ—Ä–æ–±–∞?
            disease_to_unit = som_data.get('disease_to_unit', {})
            if test_disease in disease_to_unit:
                correct_unit = disease_to_unit[test_disease]
                print(f"      –ü—Ä–∞–≤–∏–ª—å–Ω–∏–π —é–Ω—ñ—Ç: {correct_unit}")
            elif disease_names := som_data.get('disease_names', []):
                if test_disease in disease_names:
                    print(f"      –•–≤–æ—Ä–æ–±–∞ —î –≤ disease_names")


def diagnose_nn_prediction(database, som_data, nn_checkpoint):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ NN –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å"""
    print_header("–ö–†–û–ö 5: NN Prediction (—Ä—É—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)")
    
    if not all([database, som_data, nn_checkpoint]):
        print("   ‚ùå –ü–æ—Ç—Ä—ñ–±–Ω—ñ –≤—Å—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏")
        return
    
    import torch
    from dr_case.neural_network import TwoBranchNN
    from dr_case.encoding import SymptomVocabulary
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
    model_config = nn_checkpoint.get('model_config', {})
    n_symptoms = model_config.get('n_symptoms', 460)
    n_diseases = model_config.get('n_diseases', 844)
    som_dim = model_config.get('som_dim', 10)
    
    model = TwoBranchNN(
        n_symptoms=n_symptoms,
        som_dim=som_dim,
        n_diseases=n_diseases
    )
    
    state_dict = nn_checkpoint.get('model_state') or nn_checkpoint.get('model_state_dict')
    model.load_state_dict(state_dict)
    model.eval()
    
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞: {n_symptoms} symptoms, {n_diseases} diseases")
    
    # –¢–µ—Å—Ç–æ–≤–∏–π –≤–µ–∫—Ç–æ—Ä
    db_path = project_root / "data" / "unified_disease_symptom_merged.json"
    vocab = SymptomVocabulary.from_database(str(db_path))
    
    test_disease = list(database.keys())[0]
    test_symptoms = database[test_disease].get('symptoms', [])[:5]
    
    print(f"\n   üß™ –¢–µ—Å—Ç: {test_disease}")
    print(f"      –°–∏–º–ø—Ç–æ–º–∏: {test_symptoms}")
    
    # –ö–æ–¥—É—î–º–æ —Å–∏–º–ø—Ç–æ–º–∏
    symptom_vector = np.zeros(n_symptoms)
    for symptom in test_symptoms:
        if vocab.has_symptom(symptom):
            idx = vocab.symptom_to_index(symptom)
            if idx < n_symptoms:
                symptom_vector[idx] = 1.0
    
    # SOM membership (—Å–ø—Ä–æ—â–µ–Ω–æ)
    som_membership = np.zeros(som_dim)
    som_membership[0] = 1.0  # BMU
    
    # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    with torch.no_grad():
        x_symptoms = torch.FloatTensor(symptom_vector).unsqueeze(0)
        x_som = torch.FloatTensor(som_membership).unsqueeze(0)
        
        output = model(x_symptoms, x_som)
        probs = torch.sigmoid(output).squeeze().numpy()
    
    # –¢–æ–ø-10 –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
    disease_names = nn_checkpoint.get('disease_names', [])
    
    top_indices = np.argsort(probs)[-10:][::-1]
    
    print(f"\n   üìä –¢–æ–ø-10 –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å:")
    for i, idx in enumerate(top_indices):
        if idx < len(disease_names):
            name = disease_names[idx]
            prob = probs[idx]
            marker = "‚úÖ" if name == test_disease else ""
            print(f"      {i+1}. {name}: {prob:.4f} {marker}")
    
    # –ü–æ–∑–∏—Ü—ñ—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    if test_disease in disease_names:
        correct_idx = disease_names.index(test_disease)
        correct_prob = probs[correct_idx]
        rank = (probs > correct_prob).sum() + 1
        print(f"\n   üìä –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å '{test_disease}':")
        print(f"      –ü–æ–∑–∏—Ü—ñ—è: {rank}")
        print(f"      –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å: {correct_prob:.4f}")
    else:
        print(f"\n   ‚ùå '{test_disease}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ disease_names!")


def main():
    print("=" * 70)
    print("Dr.Case ‚Äî –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê PIPELINE")
    print("=" * 70)
    
    # –ö—Ä–æ–∫ 1
    database = diagnose_database()
    
    # –ö—Ä–æ–∫ 2
    som_data = diagnose_som()
    
    # –ö—Ä–æ–∫ 3
    nn_checkpoint = diagnose_nn()
    
    # –ö—Ä–æ–∫ 4
    if database and som_data:
        diagnose_candidate_selection(database, som_data)
    
    # –ö—Ä–æ–∫ 5
    if database and som_data and nn_checkpoint:
        diagnose_nn_prediction(database, som_data, nn_checkpoint)
    
    print_header("–í–ò–°–ù–û–í–ö–ò")
    print("""
   –ú–æ–∂–ª–∏–≤—ñ –ø—Ä–∏—á–∏–Ω–∏ Recall = 0:
   
   1. ‚ùì –°–∏–º–ø—Ç–æ–º–∏ –Ω–µ –∑–±—ñ–≥–∞—é—Ç—å—Å—è –º—ñ–∂ –±–∞–∑–æ—é —Ç–∞ —Å–ª–æ–≤–Ω–∏–∫–æ–º
   2. ‚ùì unit_to_diseases –º–∞—î –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á—ñ–≤
   3. ‚ùì disease_names –≤ SOM ‚â† disease_names –≤ NN
   4. ‚ùì NN –Ω–µ –Ω–∞–≤—á–µ–Ω–∞ (–≤—Å—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ ~–æ–¥–Ω–∞–∫–æ–≤—ñ)
   5. ‚ùì –¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ –≥–µ–Ω–µ—Ä—É—é—Ç—å—Å—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
   
   –ó–∞–ø—É—Å—Ç–∏ —Ü–µ–π —Å–∫—Ä–∏–ø—Ç —ñ –ø–µ—Ä–µ–≤—ñ—Ä –∫–æ–∂–µ–Ω –∫—Ä–æ–∫!
""")


if __name__ == "__main__":
    main()
